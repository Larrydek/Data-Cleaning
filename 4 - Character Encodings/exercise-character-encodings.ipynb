{"cells":[{"cell_type":"markdown","metadata":{},"source":["**This notebook is an exercise in the [Data Cleaning](https://www.kaggle.com/learn/data-cleaning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/character-encodings).**\n","\n","---\n"]},{"cell_type":"markdown","metadata":{},"source":["In this exercise, you'll apply what you learned in the **Character encodings** tutorial.\n","\n","# Setup\n","\n","The questions below will give you feedback on your work. Run the following cell to set up the feedback system."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-04T07:53:57.262734Z","iopub.status.busy":"2022-05-04T07:53:57.261778Z","iopub.status.idle":"2022-05-04T07:53:57.353617Z","shell.execute_reply":"2022-05-04T07:53:57.353023Z","shell.execute_reply.started":"2022-05-04T07:53:57.262631Z"},"trusted":true},"outputs":[],"source":["from learntools.core import binder\n","binder.bind(globals())\n","from learntools.data_cleaning.ex4 import *\n","print(\"Setup Complete\")"]},{"cell_type":"markdown","metadata":{},"source":["# Get our environment set up\n","\n","The first thing we'll need to do is load in the libraries we'll be using."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-04T07:54:19.047644Z","iopub.status.busy":"2022-05-04T07:54:19.046857Z","iopub.status.idle":"2022-05-04T07:54:19.052006Z","shell.execute_reply":"2022-05-04T07:54:19.051256Z","shell.execute_reply.started":"2022-05-04T07:54:19.047595Z"},"trusted":true},"outputs":[],"source":["# modules we'll use\n","import pandas as pd\n","import numpy as np\n","\n","# helpful character encoding module\n","import chardet\n","\n","# set seed for reproducibility\n","np.random.seed(0)"]},{"cell_type":"markdown","metadata":{},"source":["# 1) What are encodings?\n","\n","You're working with a dataset composed of bytes.  Run the code cell below to print a sample entry."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-04T07:54:46.580419Z","iopub.status.busy":"2022-05-04T07:54:46.580156Z","iopub.status.idle":"2022-05-04T07:54:46.585046Z","shell.execute_reply":"2022-05-04T07:54:46.584424Z","shell.execute_reply.started":"2022-05-04T07:54:46.580392Z"},"trusted":true},"outputs":[],"source":["sample_entry = b'\\xa7A\\xa6n'\n","print(sample_entry)\n","print('data type:', type(sample_entry))"]},{"cell_type":"markdown","metadata":{},"source":["You notice that it doesn't use the standard UTF-8 encoding. \n","\n","Use the next code cell to create a variable `new_entry` that changes the encoding from `\"big5-tw\"` to `\"utf-8\"`.  `new_entry` should have the bytes datatype."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-04T08:01:19.435793Z","iopub.status.busy":"2022-05-04T08:01:19.434972Z","iopub.status.idle":"2022-05-04T08:01:19.443482Z","shell.execute_reply":"2022-05-04T08:01:19.442777Z","shell.execute_reply.started":"2022-05-04T08:01:19.435747Z"},"trusted":true},"outputs":[],"source":["new_entry = sample_entry.decode('big5-tw')\n","print(type(new_entry))\n","new_entry = new_entry.encode('utf-8')\n","print(type(new_entry))\n","\n","# Check your answer\n","q1.check()"]},{"cell_type":"markdown","metadata":{},"source":["# 2) Reading in files with encoding problems\n","\n","Use the code cell below to read in this file at path `\"../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv\"`.  \n","\n","Figure out what the correct encoding should be and read in the file to a DataFrame `police_killings`."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-04T08:15:47.065665Z","iopub.status.busy":"2022-05-04T08:15:47.065262Z","iopub.status.idle":"2022-05-04T08:15:48.037573Z","shell.execute_reply":"2022-05-04T08:15:48.037010Z","shell.execute_reply.started":"2022-05-04T08:15:47.065625Z"},"trusted":true},"outputs":[],"source":["# TODO: Load in the DataFrame correctly.\n","with open(\"../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv\", \"rb\") as police_killings:\n","    result = chardet.detect(police_killings.read(10000))\n","\n","print(result)\n","police_killings = pd.read_csv(\"../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv\", encoding='Windows-1252')\n","# Check your answer\n","q2.check()"]},{"cell_type":"markdown","metadata":{},"source":["Feel free to use any additional code cells for supplemental work.  To get credit for finishing this question, you'll need to run `q2.check()` and get a result of **Correct**."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-04T08:16:43.468118Z","iopub.status.busy":"2022-05-04T08:16:43.467821Z","iopub.status.idle":"2022-05-04T08:16:44.426588Z","shell.execute_reply":"2022-05-04T08:16:44.425764Z","shell.execute_reply.started":"2022-05-04T08:16:43.468085Z"},"trusted":true},"outputs":[],"source":["with open(\"../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv\", \"rb\") as police_killings:\n","    result = chardet.detect(police_killings.read(100000))\n","    \n","print(result)\n","police_killings = pd.read_csv(\"../input/fatal-police-shootings-in-the-us/PoliceKillingsUS.csv\", encoding='Windows-1252')\n","\n","q2.check()\n"]},{"cell_type":"markdown","metadata":{},"source":["# 3) Saving your files with UTF-8 encoding\n","\n","Save a version of the police killings dataset to CSV with UTF-8 encoding.  Your answer will be marked correct after saving this file.  \n","\n","Note: When using the `to_csv()` method, supply only the name of the file (e.g., `\"my_file.csv\"`).  This saves the file at the filepath `\"/kaggle/working/my_file.csv\"`."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-04T08:18:37.545449Z","iopub.status.busy":"2022-05-04T08:18:37.545033Z","iopub.status.idle":"2022-05-04T08:18:37.573934Z","shell.execute_reply":"2022-05-04T08:18:37.573183Z","shell.execute_reply.started":"2022-05-04T08:18:37.545409Z"},"trusted":true},"outputs":[],"source":["# TODO: Save the police killings dataset to CSV\n","police_killings.to_csv('my_file.csv')\n","\n","# Check your answer\n","q3.check()"]},{"cell_type":"markdown","metadata":{},"source":["# (Optional) More practice\n","\n","Check out [this dataset of files in different character encodings](https://www.kaggle.com/rtatman/character-encoding-examples). Can you read in all the files with their original encodings and them save them out as UTF-8 files?\n","\n","If you have a file that's in UTF-8 but has just a couple of weird-looking characters in it, you can try out the [ftfy module](https://ftfy.readthedocs.io/en/latest/#) and see if it helps. \n","\n","# Keep going\n","\n","In the final lesson, learn how to [**clean up inconsistent text entries**](https://www.kaggle.com/alexisbcook/inconsistent-data-entry) in your dataset."]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","\n","\n","\n","*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/data-cleaning/discussion) to chat with other learners.*"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":2647,"sourceId":4395,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
