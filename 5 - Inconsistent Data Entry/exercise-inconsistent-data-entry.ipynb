{"cells":[{"cell_type":"markdown","metadata":{},"source":["**This notebook is an exercise in the [Data Cleaning](https://www.kaggle.com/learn/data-cleaning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/inconsistent-data-entry).**\n","\n","---\n"]},{"cell_type":"markdown","metadata":{},"source":["In this exercise, you'll apply what you learned in the **Inconsistent data entry** tutorial.\n","\n","# Setup\n","\n","The questions below will give you feedback on your work. Run the following cell to set up the feedback system."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-04T09:46:44.039540Z","iopub.status.busy":"2022-05-04T09:46:44.039105Z","iopub.status.idle":"2022-05-04T09:46:44.044531Z","shell.execute_reply":"2022-05-04T09:46:44.043705Z","shell.execute_reply.started":"2022-05-04T09:46:44.039495Z"},"trusted":true},"outputs":[],"source":["from learntools.core import binder\n","binder.bind(globals())\n","from learntools.data_cleaning.ex5 import *\n","print(\"Setup Complete\")"]},{"cell_type":"markdown","metadata":{},"source":["# Get our environment set up\n","\n","The first thing we'll need to do is load in the libraries and dataset we'll be using.  We use the same dataset from the tutorial."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-04T09:46:44.053031Z","iopub.status.busy":"2022-05-04T09:46:44.052547Z","iopub.status.idle":"2022-05-04T09:46:44.070545Z","shell.execute_reply":"2022-05-04T09:46:44.069792Z","shell.execute_reply.started":"2022-05-04T09:46:44.053002Z"},"trusted":true},"outputs":[],"source":["# modules we'll use\n","import pandas as pd\n","import numpy as np\n","\n","# helpful modules\n","import fuzzywuzzy\n","from fuzzywuzzy import process\n","import chardet\n","\n","# read in all our data\n","professors = pd.read_csv(\"../input/pakistan-intellectual-capital/pakistan_intellectual_capital.csv\")\n","\n","# set seed for reproducibility\n","np.random.seed(0)"]},{"cell_type":"markdown","metadata":{},"source":["Next, we'll redo all of the work that we did in the tutorial."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-04T09:46:44.072684Z","iopub.status.busy":"2022-05-04T09:46:44.072049Z","iopub.status.idle":"2022-05-04T09:46:44.086145Z","shell.execute_reply":"2022-05-04T09:46:44.085171Z","shell.execute_reply.started":"2022-05-04T09:46:44.072648Z"},"trusted":true},"outputs":[],"source":["# convert to lower case\n","professors['Country'] = professors['Country'].str.lower()\n","# remove trailing white spaces\n","professors['Country'] = professors['Country'].str.strip()\n","\n","# get the top 10 closest matches to \"south korea\"\n","countries = professors['Country'].unique()\n","matches = fuzzywuzzy.process.extract(\"south korea\", countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n","\n","def replace_matches_in_column(df, column, string_to_match, min_ratio = 47):\n","    # get a list of unique strings\n","    strings = df[column].unique()\n","    \n","    # get the top 10 closest matches to our input string\n","    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n","                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n","\n","    # only get matches with a ratio > 90\n","    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n","\n","    # get the rows of all the close matches in our dataframe\n","    rows_with_matches = df[column].isin(close_matches)\n","\n","    # replace all rows with close matches with the input matches \n","    df.loc[rows_with_matches, column] = string_to_match\n","    \n","    # let us know the function's done\n","    print(\"All done!\")\n","    \n","replace_matches_in_column(df=professors, column='Country', string_to_match=\"south korea\")\n","countries = professors['Country'].unique()"]},{"cell_type":"markdown","metadata":{},"source":["# 1) Examine another column\n","\n","Write code below to take a look at all the unique values in the \"Graduated from\" column."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-04T09:46:44.088109Z","iopub.status.busy":"2022-05-04T09:46:44.087465Z","iopub.status.idle":"2022-05-04T09:46:44.105109Z","shell.execute_reply":"2022-05-04T09:46:44.103945Z","shell.execute_reply.started":"2022-05-04T09:46:44.088073Z"},"trusted":true},"outputs":[],"source":["professors['Graduated from'].unique()"]},{"cell_type":"markdown","metadata":{},"source":["Do you notice any inconsistencies in the data?  Can any of the inconsistencies in the data be fixed by removing white spaces at the beginning and end of cells?\n","\n","Once you have answered these questions, run the code cell below to get credit for your work."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-04T09:46:44.107838Z","iopub.status.busy":"2022-05-04T09:46:44.107333Z","iopub.status.idle":"2022-05-04T09:46:44.115507Z","shell.execute_reply":"2022-05-04T09:46:44.114862Z","shell.execute_reply.started":"2022-05-04T09:46:44.107796Z"},"trusted":true},"outputs":[],"source":["# Check your answer (Run this code cell to receive credit!)\n","q1.check()"]},{"cell_type":"markdown","metadata":{},"source":["# 2) Do some text pre-processing\n","\n","Convert every entry in the \"Graduated from\" column in the `professors` DataFrame to remove white spaces at the beginning and end of cells."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-04T09:46:44.126652Z","iopub.status.busy":"2022-05-04T09:46:44.126416Z","iopub.status.idle":"2022-05-04T09:46:44.141629Z","shell.execute_reply":"2022-05-04T09:46:44.140714Z","shell.execute_reply.started":"2022-05-04T09:46:44.126616Z"},"trusted":true},"outputs":[],"source":["# TODO: Your code here\n","professors['Graduated from'] = professors['Graduated from'].str.strip()\n","\n","# Check your answer\n","q2.check()"]},{"cell_type":"markdown","metadata":{},"source":["# 3) Continue working with countries\n","\n","In the tutorial, we focused on cleaning up inconsistencies in the \"Country\" column.  Run the code cell below to view the list of unique values that we ended with."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-04T09:46:44.149660Z","iopub.status.busy":"2022-05-04T09:46:44.148906Z","iopub.status.idle":"2022-05-04T09:46:44.161333Z","shell.execute_reply":"2022-05-04T09:46:44.160475Z","shell.execute_reply.started":"2022-05-04T09:46:44.149617Z"},"trusted":true},"outputs":[],"source":["# get all the unique values in the 'City' column\n","countries = professors['Country'].unique()\n","\n","# sort them alphabetically and then take a closer look\n","countries.sort()\n","countries"]},{"cell_type":"markdown","metadata":{},"source":["Take another look at the \"Country\" column and see if there's any more data cleaning we need to do.\n","\n","It looks like 'usa' and 'usofa' should be the same country.  Correct the \"Country\" column in the dataframe to replace 'usofa' with 'usa'.\n","\n","**Use the most recent version of the DataFrame (with the whitespaces at the beginning and end of cells removed) from question 2.**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-05-04T09:46:44.163979Z","iopub.status.busy":"2022-05-04T09:46:44.163313Z","iopub.status.idle":"2022-05-04T09:46:44.179393Z","shell.execute_reply":"2022-05-04T09:46:44.178542Z","shell.execute_reply.started":"2022-05-04T09:46:44.163937Z"},"trusted":true},"outputs":[],"source":["# TODO: Your code here!\n","matches = fuzzywuzzy.process.extract('usa', countries, limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n","print(matches)\n","\n","replace_matches_in_column(df=professors, column='Country', string_to_match='usa', min_ratio=70)\n","\n","# Check your answer\n","q3.check()"]},{"cell_type":"markdown","metadata":{},"source":["# Congratulations!\n","\n","Congratulations for completing the **Data Cleaning** course on Kaggle Learn!\n","\n","To practice your new skills, you're encouraged to download and investigate some of [Kaggle's Datasets](https://www.kaggle.com/datasets)."]},{"cell_type":"markdown","metadata":{},"source":["---\n","\n","\n","\n","\n","*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/data-cleaning/discussion) to chat with other learners.*"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":819513,"sourceId":1402182,"sourceType":"datasetVersion"}],"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
